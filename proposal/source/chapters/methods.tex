\section{Methods}
Text classification is a supervised learning problem that given :
\begin{itemize}
    \item a description \( d \in X \) of a document, where \(X\) is the document space, and
    \item a fixed set of classes \(C = {c_1,c_2,...c_n}\), also known as tags or labels, 
\end{itemize}
has the goal to find a model that, trained with a training set \(D\) of labelled documents (\(<d,c> \in X \times C\)), is able to generalize.
In particular, in the dataset ~\cite{dataset-r8r52ohsumed} that will be used for making the comparisons that will explained later, \(<d,c>\) are couples like the following : 
\begin{equation}
    <d,c> = <champion\hspace{0.15cm}product\hspace{0.15cm}approv\hspace{0.15cm}stock\hspace{0.15cm}split\hspace{0.15cm}mln\hspace{0.15cm}sale\hspace{0.15cm}billion\hspace{0.15cm}...,\hspace{0.15cm}earn>,
\end{equation}
where $earn$ is a label or a class that belongs to \(C\).
Using a learning method, a classifier \(\gamma\) is returned, which is going to map documents into classes : \(\gamma : X \rightarrow C\).
\newline
Therefore, to solve the above explained problem the following learning methods~\cite{paper-text-classification-algorithms} will be implemented:
\begin{itemize}
    \item Machine Learning Methods :
        \begin{itemize}
            \item Rocchio Classifier.
            \item Naive Bayes Classifier.
            \item K-Nearest Neighbor (KNN).
            \item Support Vector Machine (SVM).
            \item Decision Tree.
            \item Boosting/Bagging methods (Random Forest, Adaboost, CatBoost).
            \item Conditional Random Field.
            \item Word Vectors.
        \end{itemize}
    \item Deep Learning Methods :        
        \begin{itemize}
            \item Recurrent Neural Networks (RNN).
            \item Convolutional Neural Network (CNN).
            \item Recurrent Convolutional Neural Networks (RCNN).
            \item Graph Convolution Neural Network (GCNN)~\cite{paper-graph-convolution-network}.
        \end{itemize}
\end{itemize}











%In text classification, it is given a description $ d \in X $ of a document, where $X$ is %the document space; and a fixed set of classes $C={c1,â€¦cn}$. Classes are also called tags %or labels. We are given a training set $D$ of labeled documents $<d, c>$, where $<d, c> %\in X \times C$.

%For example, using the dataset we chose ('$oh-r8-r52$'):



%Using a learning method, we then learn a classifier $\gamma$ that maps documents to classes:
%\begin{equation}
%    T : X \rightarrow C
%\end{equation}


%This type of learning is supervised, in fact our dataset consists of labelled examples, %meaning that each data point contains features and an associated label.

