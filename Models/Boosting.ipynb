{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95dbdb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "import csv\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7040ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you need to download the dataset\n",
    "\n",
    "import opendatasets as od\n",
    "od.download(\"https://www.kaggle.com/datasets/weipengfei/ohr8r52\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e43cb531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./ohr8r52\\oh\\oh-dev-stemmed.csv\n",
      "./ohr8r52\\oh\\oh-test-stemmed.csv\n",
      "./ohr8r52\\oh\\oh-train-stemmed.csv\n",
      "./ohr8r52\\r52\\r52-dev-stemmed.csv\n",
      "./ohr8r52\\r52\\r52-test-stemmed.csv\n",
      "./ohr8r52\\r52\\r52-train-stemmed.csv\n",
      "./ohr8r52\\r8\\r8-dev-stemmed.csv\n",
      "./ohr8r52\\r8\\r8-test-stemmed.csv\n",
      "./ohr8r52\\r8\\r8-train-stemmed.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('./ohr8r52'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d67b784",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>edge</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>champion product approv stock split champion p...</td>\n",
       "      <td>champion product approv stock split champion p...</td>\n",
       "      <td>earn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comput termin system cpml complet sale comput ...</td>\n",
       "      <td>comput termin system cpml complet sale comput ...</td>\n",
       "      <td>acq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cobanco inc cbco year net shr ct dlr net asset...</td>\n",
       "      <td>cobanco inc cbco year net shr ct dlr net asset...</td>\n",
       "      <td>earn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>intern inc qtr jan oper shr loss two ct profit...</td>\n",
       "      <td>intern inc qtr jan oper shr loss two ct profit...</td>\n",
       "      <td>earn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brown forman inc bfd qtr net shr dlr ct net ml...</td>\n",
       "      <td>brown forman inc bfd qtr net shr dlr ct net ml...</td>\n",
       "      <td>earn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  champion product approv stock split champion p...   \n",
       "1  comput termin system cpml complet sale comput ...   \n",
       "2  cobanco inc cbco year net shr ct dlr net asset...   \n",
       "3  intern inc qtr jan oper shr loss two ct profit...   \n",
       "4  brown forman inc bfd qtr net shr dlr ct net ml...   \n",
       "\n",
       "                                                edge intent  \n",
       "0  champion product approv stock split champion p...   earn  \n",
       "1  comput termin system cpml complet sale comput ...    acq  \n",
       "2  cobanco inc cbco year net shr ct dlr net asset...   earn  \n",
       "3  intern inc qtr jan oper shr loss two ct profit...   earn  \n",
       "4  brown forman inc bfd qtr net shr dlr ct net ml...   earn  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_r8 = pd.read_csv('./ohr8r52/r8/r8-train-stemmed.csv')\n",
    "test_r8 = pd.read_csv('./ohr8r52/r8/r8-test-stemmed.csv')\n",
    "train_r8.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b327a3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GloveVectorizer:\n",
    "  def __init__(self):\n",
    "    # load in pre-trained word vectors\n",
    "    print('Loading word vectors...')\n",
    "    word2vec = {}\n",
    "    embedding = []\n",
    "    idx2word = []\n",
    "    with open('glove.6B.50d.txt',encoding=\"utf8\") as f:\n",
    "      # is just a space-separated text file in the format:\n",
    "      # word vec[0] vec[1] vec[2] ...\n",
    "      for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vec = np.asarray(values[1:], dtype='float32')\n",
    "        word2vec[word] = vec\n",
    "        embedding.append(vec)\n",
    "        idx2word.append(word)\n",
    "    print('Found %s word vectors.' % len(word2vec))\n",
    "\n",
    "    self.word2vec = word2vec\n",
    "    self.embedding = np.array(embedding)\n",
    "    self.word2idx = {v:k for k,v in enumerate(idx2word)}\n",
    "    self.V, self.D = self.embedding.shape\n",
    "\n",
    "  def fit(self, data):\n",
    "    pass\n",
    "\n",
    "  def transform(self, data):\n",
    "    X = np.zeros((len(data), self.D))\n",
    "    n = 0\n",
    "    emptycount = 0\n",
    "    for sentence in data:\n",
    "      tokens = sentence.lower().split()\n",
    "      vecs = []\n",
    "      for word in tokens:\n",
    "        if word in self.word2vec:\n",
    "          vec = self.word2vec[word]\n",
    "          vecs.append(vec)\n",
    "      if len(vecs) > 0:\n",
    "        vecs = np.array(vecs)\n",
    "        X[n] = vecs.mean(axis=0)\n",
    "      else:\n",
    "        emptycount += 1\n",
    "      n += 1\n",
    "    print(\"Numer of samples with no words found: %s / %s\" % (emptycount, len(data)))\n",
    "    return X\n",
    "\n",
    "  def fit_transform(self, data):\n",
    "    self.fit(data)\n",
    "    return self.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "167245db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word vectors...\n",
      "Found 400000 word vectors.\n",
      "Numer of samples with no words found: 0 / 4937\n",
      "Numer of samples with no words found: 0 / 2189\n"
     ]
    }
   ],
   "source": [
    "vectorizer = GloveVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_r8.text)\n",
    "Y_train = train_r8.intent\n",
    "\n",
    "X_test = vectorizer.transform(test_r8.text)\n",
    "Y_test = test_r8.intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40cff591",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf = GradientBoostingClassifier(n_estimators=100)\n",
    "text_clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbb876da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acq       0.92      0.92      0.92       696\n",
      "       crude       0.95      0.87      0.91       121\n",
      "        earn       0.95      0.98      0.96      1083\n",
      "       grain       0.43      0.30      0.35        10\n",
      "    interest       0.91      0.65      0.76        81\n",
      "    money-fx       0.57      0.46      0.51        87\n",
      "        ship       0.81      0.81      0.81        36\n",
      "       trade       0.68      0.87      0.76        75\n",
      "\n",
      "    accuracy                           0.91      2189\n",
      "   macro avg       0.78      0.73      0.75      2189\n",
      "weighted avg       0.91      0.91      0.91      2189\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = text_clf.predict(X_test)\n",
    "print(metrics.classification_report(Y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "893e62ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numer of samples with no words found: 0 / 3021\n",
      "Numer of samples with no words found: 0 / 4043\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         C01       0.20      0.21      0.20       102\n",
      "         C02       0.07      0.04      0.05        50\n",
      "         C03       0.08      0.07      0.08        29\n",
      "         C04       0.51      0.69      0.58       600\n",
      "         C05       0.29      0.11      0.16       140\n",
      "         C06       0.32      0.20      0.24       178\n",
      "         C07       0.06      0.03      0.04        34\n",
      "         C08       0.24      0.06      0.10       129\n",
      "         C09       0.00      0.00      0.00        28\n",
      "         C10       0.39      0.29      0.33       342\n",
      "         C11       0.18      0.08      0.11        76\n",
      "         C12       0.15      0.06      0.08       187\n",
      "         C13       0.52      0.22      0.31       103\n",
      "         C14       0.52      0.76      0.62       590\n",
      "         C15       0.08      0.04      0.05        79\n",
      "         C16       0.09      0.04      0.06        70\n",
      "         C17       0.39      0.18      0.25       132\n",
      "         C18       0.35      0.37      0.36       155\n",
      "         C19       0.03      0.02      0.03        46\n",
      "         C20       0.33      0.31      0.32       231\n",
      "         C21       0.46      0.45      0.46       313\n",
      "         C22       0.00      0.00      0.00        10\n",
      "         C23       0.17      0.28      0.21       419\n",
      "\n",
      "    accuracy                           0.37      4043\n",
      "   macro avg       0.24      0.20      0.20      4043\n",
      "weighted avg       0.35      0.37      0.35      4043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#USING OH\n",
    "\n",
    "train_r8 = pd.read_csv('./ohr8r52/oh/oh-train-stemmed.csv')\n",
    "test_r8 = pd.read_csv('./ohr8r52/oh/oh-test-stemmed.csv')\n",
    "train_r8.head()\n",
    "\n",
    "#Vectorize the new dataset entries\n",
    "X_train = vectorizer.fit_transform(train_r8.text)\n",
    "Y_train = train_r8.intent\n",
    "X_test = vectorizer.transform(test_r8.text)\n",
    "Y_test = test_r8.intent\n",
    "\n",
    "#Compute a new model with the new dataset\n",
    "text_clf = GradientBoostingClassifier(n_estimators=100)\n",
    "text_clf.fit(X_train, Y_train)\n",
    "\n",
    "#Predict\n",
    "predicted = text_clf.predict(X_test)\n",
    "print(metrics.classification_report(Y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "706f69fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numer of samples with no words found: 0 / 5879\n",
      "Numer of samples with no words found: 0 / 2568\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "            acq       0.87      0.89      0.88       696\n",
      "           alum       0.70      0.37      0.48        19\n",
      "            bop       0.38      0.33      0.35         9\n",
      "        carcass       0.50      0.20      0.29         5\n",
      "          cocoa       0.33      0.07      0.11        15\n",
      "         coffee       0.50      0.50      0.50        22\n",
      "         copper       0.17      0.08      0.11        13\n",
      "         cotton       1.00      0.11      0.20         9\n",
      "            cpi       0.53      0.53      0.53        17\n",
      "            cpu       0.00      0.00      0.00         1\n",
      "          crude       0.67      0.73      0.70       121\n",
      "            dlr       0.00      0.00      0.00         3\n",
      "           earn       0.91      0.96      0.93      1083\n",
      "           fuel       0.17      0.14      0.15         7\n",
      "            gas       0.00      0.00      0.00         8\n",
      "            gnp       0.57      0.87      0.68        15\n",
      "           gold       0.59      0.50      0.54        20\n",
      "          grain       0.10      0.10      0.10        10\n",
      "           heat       0.33      0.50      0.40         4\n",
      "        housing       0.00      0.00      0.00         2\n",
      "         income       0.33      0.25      0.29         4\n",
      "    instal-debt       0.00      0.00      0.00         1\n",
      "       interest       0.82      0.57      0.67        81\n",
      "            ipi       0.40      0.18      0.25        11\n",
      "     iron-steel       0.00      0.00      0.00        12\n",
      "            jet       0.00      0.00      0.00         1\n",
      "           jobs       0.33      0.25      0.29        12\n",
      "           lead       0.00      0.00      0.00         4\n",
      "            lei       1.00      0.67      0.80         3\n",
      "      livestock       0.00      0.00      0.00         5\n",
      "         lumber       0.00      0.00      0.00         4\n",
      "      meal-feed       0.00      0.00      0.00         1\n",
      "       money-fx       0.51      0.43      0.46        87\n",
      "   money-supply       0.45      0.50      0.47        28\n",
      "        nat-gas       0.00      0.00      0.00        12\n",
      "         nickel       0.00      0.00      0.00         1\n",
      "         orange       0.67      0.44      0.53         9\n",
      "       pet-chem       0.00      0.00      0.00         6\n",
      "       platinum       0.00      0.00      0.00         2\n",
      "         potato       0.00      0.00      0.00         3\n",
      "       reserves       0.23      0.25      0.24        12\n",
      "         retail       0.00      0.00      0.00         1\n",
      "         rubber       0.40      0.22      0.29         9\n",
      "           ship       0.65      0.61      0.63        36\n",
      "strategic-metal       0.00      0.00      0.00         6\n",
      "          sugar       0.44      0.64      0.52        25\n",
      "            tea       0.00      0.00      0.00         3\n",
      "            tin       0.20      0.10      0.13        10\n",
      "          trade       0.61      0.72      0.66        75\n",
      "        veg-oil       0.22      0.18      0.20        11\n",
      "            wpi       0.29      0.22      0.25         9\n",
      "           zinc       0.12      0.20      0.15         5\n",
      "\n",
      "       accuracy                           0.79      2568\n",
      "      macro avg       0.31      0.26      0.27      2568\n",
      "   weighted avg       0.77      0.79      0.77      2568\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\simon\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\simon\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\simon\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#USING r52\n",
    "\n",
    "train_r8 = pd.read_csv('./ohr8r52/r52/r52-train-stemmed.csv')\n",
    "test_r8 = pd.read_csv('./ohr8r52/r52/r52-test-stemmed.csv')\n",
    "train_r8.head()\n",
    "\n",
    "#Vectorize the new dataset entries\n",
    "X_train = vectorizer.fit_transform(train_r8.text)\n",
    "Y_train = train_r8.intent\n",
    "X_test = vectorizer.transform(test_r8.text)\n",
    "Y_test = test_r8.intent\n",
    "\n",
    "#Compute a new model with the new dataset\n",
    "text_clf = GradientBoostingClassifier(n_estimators=100)\n",
    "text_clf.fit(X_train, Y_train)\n",
    "\n",
    "#Predict\n",
    "predicted = text_clf.predict(X_test)\n",
    "print(metrics.classification_report(Y_test, predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
